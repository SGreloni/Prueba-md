## Acerca de mí

Soy un estudiante de la carrera de Actuario en Economía en la Universidad de Buenos Aires, con una gran curiosidad y un especial interés por la Ciencia de Datos, la Estadística y la Inteligencia Artificial. 

#### Educación

-**Universidad de Buenos Aires** *(03/2019 - Actualidad)*   
Promedio 8,5 *(28/33 materias)*


-**Colegio Nacional de Buenos Aires** *(03/2014 - 11/2018)*  
Promedio 8,22 


## Curriculum Vitae

[CV](https://drive.google.com/file/d/1et4YOYs3aJySvBQDTHJUBVC_vf2R_G4x/view?usp=sharing)


## Certificiaciones
[Certificaciones](Certificaciones)

## Proyectos

### [Proyecto 1.1:  Análisis y predicción de precios en Airbnb](https://github.com/SGreloni/prediccion-precios-Airbnb/blob/master/Predictor%20de%20precios%20de%20Airbnb%20.ipynb)

Realicé un análisis sobre datos de 20000 propiedades listadas en Airbnb y entrené un modelo de regresión que predice el precio por noche al que debería estar ofrecida la propiedad según características como su capacidad, cantidad de baños, número de dormitorios, etcétera.

Herramientas utilizadas:
* Pandas (limpieza de datos)
* Matplotlib y Seaborn (visualización de datos)
* Scikit-Learn (*feature engineering* y ajuste de hiperparámetros)
* XGBoost (*Machine Learning*: regresión)
* Markdown y LaTex (legiblididad y publicación de textos digitales)

![Disposición de propiedades de Airbnb en CABA](Proyectos%20(img)/Mapa%20airbnb.png)

### [Proyecto 1.2:  Aplicación Web para prediccion de precios de Airbnb](https://sgreloni-prediccion-precios-airbnb-streamlit-7qdwlt.streamlit.app/)

Utilizando el modelo de inteligencia artifical entrenado en **Proyecto 1: Análisis y predicción de precios en Airbnb** construí una aplicación web con una interfaz estética e intuitiva para tasar la estadía por noche según el input obtenido del usuario.

Herramientas utilizadas:
* Streamlit (generación de aplicaciónes Web)
* Geopy (servicios de geocodificación)
* Heroku (despliegue en la nube)
* Git (control de versiones)

### [Proyecto 2: SegArt](https://sgreloni-segart-artapp-nvijob.streamlit.app/)

Utilicé una aplicación no convencional del algoritmo de aprendizaje no supervisado *KMeans* como segmentador de imagen, aprovechando para explicar didácticamente como funciona y permitiendo al lector jugar con el hiperparámetro K (la cantidad de *clusters* que busca el algoritmo). Adicionalmente agregué la opción de poder modificar los colores de cada segmento o cluster con el objetivo de crear composiciones artísticas fácilmente. Para más información acerca del proceso de creación visitar el [repositorio en Github](https://github.com/SGreloni/segart) y el [Jupyter Notebook](https://github.com/SGreloni/segart/blob/master/SegArt.ipynb).

Herramientas utilizadas:
* Numpy (soporte de vectores, matrices y funciones matemáticas)
* Matplotlib (Visualización de datos -2D, 3D y animaciones-)
* KMeans -Sklearn- (*Machine Learning*: Clusterización)
* Markdown (legiblididad y publicación de textos digitales)
* PIL (soporte de manipulación de imágenes)
* Streamlit (generación de aplicaciónes Web)
* Heroku (despliegue en la nube)
* Git (control de versiones)

![Animación 3D](Proyectos%20(img)/rotation.gif)

### [Proyecto 3: Spotify Clustering Challenge](https://github.com/SGreloni/Spotify-Clustering-Challenge/blob/main/Hiring%20Process%20Challenge.ipynb)

This project is my solution to a Challenge which was part of a Hiring Process. I was asked to analyze and cluster a small sample of the Sportify Dataset having into account not only classical metrics such as Inertia but also the intuition and meaning of each cluster. For this I made an Exploratory Data Analysis and tried both DBSCAN and K-Mean on the data. For choosing the definitive clusters I made a Silhouette Diagram Analysis, manual inspection of individual instances and a visualization of the data structure using t-SNE. Finally, to help me interpet the results I fitted a Random Forest Classifier to the clusters to find, with the feature importances, the most important variables in differentiating each group.

Main tools:
* Pandas
* Matplotlib
* Seaborn
* Scikit-learn (DBSCAN, K-Means, Random Forest, t-SNE manifold learning)
* Yellowbrick (Silhouette Diagram Analysis)

![Embedding coloured by cluster](Proyectos%20(img)/t-SNE.png)

### [Economics of Financial Markets Final Project](https://github.com/SGreloni/Finance-Portfolio-Optimization-/blob/main/Suliansky%20and%20Greloni%20(Q1).pdf)

This is the final project we wrote with [Gaspar Suliansky](https://ar.linkedin.com/in/gaspar-suliansky-b1420320a) for the Economics of Financial Markets course (part of the Quantitattive Finace Masters Degree) during our exchange program to the University of Bologna, getting a grade of 30/30 Cum Laude.
We studied daily and monthly returns for different Italian assets, and provided different alocation strategies, such as mean-variance Markowitz optimizatioin and Bayesian methods, including the Black Litterman model and Jorion Shrinkage Estimator. We calculated each of these portfolios and evaluated their performance based on different statistics [using Python](https://github.com/SGreloni/Finance-Portfolio-Optimization-/blob/main/Code-Daily.ipynb)

![Efficient Frontier](https://github.com/SGreloni/Portafolio/blob/gh-pages/Proyectos%20(img)/MVP.png)



## Contacto

E-mail: Santiagogreloni@gmail.com

[Linkedin](https://www.linkedin.com/in/santiago-greloni-4892a9196) 

